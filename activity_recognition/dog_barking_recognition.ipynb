{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-56977b3f79e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#from keras import backend as K\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "#from keras import backend as K\n",
    "from keras import optimizers\n",
    "#K.set_image_dim_ordering('th')\n",
    "# setting up a random seed for reproducibility\n",
    "random_seed = 611\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "# defining function for loading the dataset\n",
    "def readData(filePath):\n",
    "    # attributes of the dataset\n",
    "    columnNames = ['label','time','x','y','z']\n",
    "    data = pd.read_csv(filePath,header = None, names=columnNames,na_values=';')\n",
    "    print(data)\n",
    "    return data\n",
    "# defining a function for feature normalization\n",
    "# (feature - mean)/stdiv\n",
    "def featureNormalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset-mu)/sigma\n",
    "# defining the function to plot a single axis data\n",
    "def plotAxis(axis,x,y,title):\n",
    "    axis.plot(x,y)\n",
    "    axis.set_title(title)\n",
    "    axis.xaxis.set_visible(False)\n",
    "    axis.set_ylim([min(y)-np.std(y),max(y)+np.std(y)])\n",
    "    axis.set_xlim([min(x),max(x)])\n",
    "    axis.grid(True)\n",
    "# defining a function to plot the data for a given activity\n",
    "def plotActivity(labelName,data):\n",
    "    fig,(ax0,ax1,ax2) = plt.subplots(nrows=3, figsize=(15,10),sharex=True)\n",
    "    plotAxis(ax0,data['time'],data['x'],'x')\n",
    "    plotAxis(ax1,data['time'],data['y'],'y')\n",
    "    plotAxis(ax2,data['time'],data['z'],'z')\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    fig.suptitle(labelName)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "# defining a window function for segmentation purposes\n",
    "def windows(data,size):\n",
    "    start = 0\n",
    "    while start< data.count():\n",
    "        yield int(start), int(start + size)\n",
    "        start+= (size/2)\n",
    "# segmenting the time series\n",
    "def segment_signal(data, window_size = 90):\n",
    "    segments = np.empty((0,window_size,3))\n",
    "    labels= np.empty((0))\n",
    "    for (start, end) in windows(data['time'],window_size):\n",
    "        x = data['x'][start:end]\n",
    "        y = data['y'][start:end]\n",
    "        z = data['z'][start:end]\n",
    "        if(len(data['time'][start:end])==window_size):\n",
    "            segments = np.vstack([segments,np.dstack([x,y,z])])\n",
    "            labels = np.append(labels,stats.mode(data['label'][start:end])[0][0])\n",
    "    return segments, labels\n",
    "''' Main Code '''\n",
    "# # # # # # # # #   reading the data   # # # # # # # # # # \n",
    "# Path of file #\n",
    "dataset = readData('./datasets/data-human.txt')\n",
    "# plotting a subset of the data to visualize\n",
    "for labelName in np.unique(dataset['label']):\n",
    "    subset = dataset[dataset['label']==labelName][:180]\n",
    "    plotActivity(labelName,subset)\n",
    "# segmenting the signal in overlapping windows of 90 samples with 50% overlap\n",
    "segments, labels = segment_signal(dataset) \n",
    "#categorically defining the classes of the activities\n",
    "labels = np.asarray(pd.get_dummies(labels),dtype = np.int8)\n",
    "# defining parameters for the input and network layers\n",
    "# we are treating each segmeent or chunk as a 2D image (90 X 3)\n",
    "numOfRows = segments.shape[1]\n",
    "numOfColumns = segments.shape[2]\n",
    "numChannels = 1\n",
    "numFilters = 128 # number of filters in Conv2D layer\n",
    "# kernal size of the Conv2D layer\n",
    "kernalSize1 = 2\n",
    "# max pooling window size\n",
    "poolingWindowSz = 2\n",
    "# number of filters in fully connected layers\n",
    "numNueronsFCL1 = 128\n",
    "numNueronsFCL2 = 128\n",
    "# split ratio for test and validation\n",
    "trainSplitRatio = 0.8\n",
    "# number of epochs\n",
    "Epochs = 10\n",
    "# batchsize\n",
    "batchSize = 10\n",
    "# number of total clases\n",
    "numClasses = labels.shape[1]\n",
    "# dropout ratio for dropout layer\n",
    "dropOutRatio = 0.2\n",
    "# reshaping the data for network input\n",
    "reshapedSegments = segments.reshape(segments.shape[0], numOfRows, numOfColumns,1)\n",
    "# splitting in training and testing data\n",
    "trainSplit = np.random.rand(len(reshapedSegments)) < trainSplitRatio\n",
    "trainX = reshapedSegments[trainSplit]\n",
    "testX = reshapedSegments[~trainSplit]\n",
    "trainX = np.nan_to_num(trainX)\n",
    "testX = np.nan_to_num(testX)\n",
    "trainY = labels[trainSplit]\n",
    "testY = labels[~trainSplit]\n",
    "\n",
    "def cnnModel():\n",
    "    model = Sequential()\n",
    "    # adding the first convolutionial layer with 32 filters and 5 by 5 kernal size, using the rectifier as the activation function\n",
    "    model.add(Conv2D(numFilters, (kernalSize1,kernalSize1),input_shape=(numOfRows, numOfColumns,1),activation='relu'))\n",
    "    # adding a maxpooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(poolingWindowSz,poolingWindowSz),padding='valid'))\n",
    "    # adding a dropout layer for the regularization and avoiding over fitting\n",
    "    model.add(Dropout(dropOutRatio))\n",
    "    # flattening the output in order to apply the fully connected layer\n",
    "    model.add(Flatten())\n",
    "    # adding first fully connected layer with 256 outputs\n",
    "    model.add(Dense(numNueronsFCL1, activation='relu'))\n",
    "    #adding second fully connected layer 128 outputs\n",
    "    model.add(Dense(numNueronsFCL2, activation='relu'))\n",
    "    # adding softmax layer for the classification\n",
    "    model.add(Dense(numClasses, activation='softmax'))\n",
    "    # Compiling the model to generate a model\n",
    "    adam = optimizers.Adam(lr = 0.001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "model = cnnModel()\n",
    "for layer in model.layers:\n",
    "    print(layer.name)\n",
    "model.fit(trainX,trainY, validation_split=1-trainSplitRatio,epochs=10,batch_size=batchSize,verbose=2)\n",
    "score = model.evaluate(testX,testY,verbose=2)\n",
    "print('Baseline Error: %.2f%%' %(100-score[1]*100))\n",
    "model.save('model_dog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 90, 3, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 89, 2, 128)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 44, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 44, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5632)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               721024    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 738,563\n",
      "Trainable params: 738,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mad_dog', 'peace_dog'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
